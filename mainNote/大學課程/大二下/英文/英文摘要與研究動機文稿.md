---
banner: 模板/banner.jpg
banner_y: "86.5"
---
## 整合式英文摘要 (Integrated English Abstract)

**字數統計 (Word Count):** 165 words

### English Version

**Abstract**

Recently, researchers have shown an increased interest in generative AI, yet the issue of explainable AI has received little attention. This paper addresses the issue of explainable AI, aiming to understand the relationship between explainable AI and user trust. We developed an analytic model that examines the impact of explainable AI on user trust. Participants included undergraduate and graduate students with prior experience using AI systems. Data for the research came from a sample of 150 individuals who interacted with generative AI tools over a two-month period, with two sets of questionnaires completed before and after their interaction. The correlations between AI transparency and perceived fairness were calculated. Results revealed that explainable AI significantly enhances user trust in AI systems. The main findings indicate that generative AI tools are perceived as highly useful and engaging by users, despite some ethical considerations. We conclude that explainable AI is crucial for fostering user trust and promoting responsible AI development, and further research should systematically investigate the long-term societal impacts of AI.

### 中文版本 (Chinese Version)

**摘要**

最近，研究人員對生成式人工智慧展現了更高的興趣，然而，可解釋人工智慧的議題卻很少受到關注。本論文探討了可解釋人工智慧的議題，旨在了解可解釋人工智慧與使用者信任之間的關係。我們建立了一個分析模型，探討可解釋人工智慧對使用者信任的影響。參與者包括具有使用人工智慧系統經驗的本科生與研究生。本研究的資料來自一個由150位參與者組成的樣本，這些人於兩個月期間與生成式人工智慧工具互動，並在互動前後完成了兩份問卷。我們計算了人工智慧透明性與使用者感知公平性之間的相關性。研究結果顯示，可解釋人工智慧顯著增強了使用者對人工智慧系統的信任。主要研究結果指出，使用者認為生成式人工智慧工具非常有用且具吸引力，儘管仍存在一些倫理考量。我們得出結論，可解釋人工智慧對於培養使用者信任和促進負責任的人工智慧發展至關重要，且未來的研究應系統性地調查人工智慧的長期社會影響。

## 錄音文稿：研究動機 (Recording Script: Motivation for This Research)

**預估時長 (Estimated Duration):** 1.5 - 1.8 minutes (可根據語速調整，此為文稿，實際語速會影響時長)

### English Version

**Introduction (Greeting)**

Hello everyone. My name is [Your Name], and today I want to share the motivation behind my research, which focuses on the critical intersection of Artificial Intelligence and human experience.

**Motivation (Part 1: The AI Landscape and Challenges)**

In the last two decades, AI-driven automation has grown significantly, and there's a recent surge of interest in generative AI. While these advancements offer incredible utility, they also present crucial challenges. Specifically, explainable AI has received little attention. The "black box" nature of many powerful AI systems impacts user trust. Research on AI ethics has produced mixed results, and there's a notable lack of focus on AI's societal impacts. Furthermore, AI transparency, particularly its effect on user perception and trust, hasn't been systematically studied. These observations formed the initial spark for my research.

**Motivation (Part 2: Personal Interest and Bridging Gaps)**

My personal interest in this area stems from observing AI's rapid integration into our lives and the public's concurrent apprehension. I believe that for AI to be responsibly adopted, it must be understood and trusted. The idea that explainable AI could foster this trust deeply resonated with me. Findings suggesting immersive VR games can distract from discomfort highlighted the profound impact of user experience, which I extended to AI interactions. My study aims to understand the relationship between explainable AI and user trust, providing insights into AI transparency. My goal is to contribute to a future where AI is not only intelligent but also understandable, trustworthy, and beneficial for all.

**Closing**

Thank you for listening.

### 中文版本 (Chinese Version)

**引言 (問候語)**

大家好。我是 [你的名字]，今天我想分享我的研究背後的動機，它主要關注人工智慧與人類體驗之間的關鍵交集。

**動機 (第一部分：人工智慧的發展與挑戰)**

過去二十年來，人工智慧驅動的自動化顯著增長，近期對生成式人工智慧的興趣也大增。儘管這些進步帶來了驚人的實用性，但也提出了關鍵挑戰。具體來說，可解釋人工智慧的議題很少受到關注。許多強大人工智慧系統的「黑箱」特性影響了使用者的信任。人工智慧倫理研究的結果不盡相同，且對人工智慧社會影響的關注明顯不足。此外，人工智慧透明性，特別是它如何影響使用者感知和信任，尚未被系統性地研究。這些觀察構成了我研究的最初火花。

**動機 (第二部分：個人興趣與彌補空白)**

我對這個領域的個人興趣源於觀察到人工智慧迅速融入我們的生活，以及同時公眾對其影響的疑慮。我相信，要使人工智慧負責任地被採用，它必須被使用者理解和信任。可解釋人工智慧可以培養這種信任的觀點深深地引起了我的共鳴。研究發現沉浸式虛擬實境遊戲可以分散不適感，這突顯了使用者體驗的深遠影響，我將此延伸到人工智慧的互動。我的研究旨在了解可解釋人工智慧與使用者信任之間的關係，並提供對人工智慧透明性的見解。我的目標是為一個人工智慧不僅智能，而且可理解、值得信賴並造福所有人的未來做出貢獻。

**結語**

謝謝大家的聆聽。