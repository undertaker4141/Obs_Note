## 3. 結果比較與討論 (Results Comparison & Discussion)

本章節將呈現各模型在七個基準測試數據集上的定量與定性結果，並深入分析其優劣差異。目前我們已完成 **Model [3] Revisiting (CVPR 2024)** 與 **Model [5] RDNet (CVPR 2025)** 的完整測試，其餘模型測試結果待補充。

### 3.1. 定量結果 (Quantitative Results)

#### **Table 1: 各模型在不同數據集上的指標比較**

以下表格彙整了各模型在七個測試數據集上的五項評估指標：PSNR（峰值信噪比，越高越好）、SSIM（結構相似性，越高越好）、NCC（歸一化互相關，越高越好）、LMSE（局部均方誤差，越低越好）以及 LPIPS（感知相似度，越低越好）。

| Dataset             | Metric | Model [1] | Model [2] | Model [3]  | Model [4] | Model [5]  | Model [6] |
| ------------------- | ------ | --------- | --------- | ---------- | --------- | ---------- | --------: |
| **CEILNet Real**    | PSNR   |           |           | N/A        |           | N/A        |           |
| **(45)**            | SSIM   |           |           | N/A        |           | N/A        |           |
|                     | NCC    |           |           | N/A        |           | N/A        |           |
|                     | LMSE   |           |           | N/A        |           | N/A        |           |
|                     | LPIPS  |           |           | N/A        |           | N/A        |           |
| **Berkeley Real**   | PSNR   |           |           | 21.64      |           | 20.75      |           |
| **(20)**            | SSIM   |           |           | 0.7978     |           | 0.7565     |           |
|                     | NCC    |           |           | 0.8477     |           | 0.8170     |           |
|                     | LMSE   |           |           | 821.51     |           | 0.0290     |           |
|                     | LPIPS  |           |           | 0.2116     |           | 0.2442     |           |
| **SIR² - Objects**  | PSNR   |           |           | 25.29      |           | **26.37**  |           |
| **(200)**           | SSIM   |           |           | 0.9016     |           | **0.9157** |           |
|                     | NCC    |           |           | 0.9865     |           | **0.9875** |           |
|                     | LMSE   |           |           | 215.24     |           | 0.0030     |           |
|                     | LPIPS  |           |           | 0.0909     |           | **0.0839** |           |
| **SIR² - Postcard** | PSNR   |           |           | 20.58      |           | **22.33**  |           |
| **(199)**           | SSIM   |           |           | 0.8728     |           | **0.8820** |           |
|                     | NCC    |           |           | 0.9342     |           | **0.9555** |           |
|                     | LMSE   |           |           | 616.87     |           | 0.0045     |           |
|                     | LPIPS  |           |           | 0.1748     |           | **0.1563** |           |
| **SIR² - Wild**     | PSNR   |           |           | 23.63      |           | **25.23**  |           |
| **(55)**            | SSIM   |           |           | 0.8696     |           | **0.9041** |           |
|                     | NCC    |           |           | 0.9317     |           | **0.9459** |           |
|                     | LMSE   |           |           | 477.03     |           | 0.0054     |           |
|                     | LPIPS  |           |           | 0.1382     |           | **0.1040** |           |
| **SIR² - All**      | PSNR   |           |           | 23.44      |           | **24.46**  |           |
| **(454)**           | SSIM   |           |           | 0.8848     |           | **0.8995** |           |
|                     | NCC    |           |           | 0.9571     |           | **0.9684** |           |
|                     | LMSE   |           |           | 405.13     |           | 0.0039     |           |
|                     | LPIPS  |           |           | 0.1292     |           | **0.1181** |           |
| **Nature**          | PSNR   |           |           | **25.11**  |           | 21.60      |           |
| **(20)**            | SSIM   |           |           | **0.8351** |           | 0.7994     |           |
|                     | NCC    |           |           | **0.9478** |           | 0.8775     |           |
|                     | LMSE   |           |           | 339.43     |           | 0.0122     |           |
|                     | LPIPS  |           |           | **0.1610** |           | 0.1708     |           |
| **NRD**             | PSNR   |           |           | 20.58      |           | **21.49**  |           |
| **(136)**           | SSIM   |           |           | 0.7221     |           | **0.7669** |           |
|                     | NCC    |           |           | 0.9045     |           | **0.9176** |           |
|                     | LMSE   |           |           | 747.58     |           | 0.0162     |           |
|                     | LPIPS  |           |           | 0.2859     |           | **0.1569** |           |

> [!NOTE]
> *註：Model [1] = ERRNet, Model [2] = KD-based, Model [3] = Revisiting (CVPR 2024), Model [4] = DSIT, Model [5] = RDNet (CVPR 2025), Model [6] = DExNet。目前已完成 Model [3] 與 Model [5] 的測試，其餘模型結果待補充。CEILNet 數據集因無 Ground Truth 而無法計算評估指標。兩模型的 LMSE 計算尺度不同（Model [3] 為絕對值，Model [5] 為歸一化值）。

---

#### **Table 2: 模型效率比較 (for SIR² only)**

| | # of Parameters (M) | FLOPs (G) | Run time (s) |
|---------|--------------------:|----------:|-------------:|
| Model [1] | | | |
| Model [2] | | | |
| Model [3] | 27.99 | 15.68 | 0.0801 |
| Model [4] | | | |
| Model [5] | 266.43 | 175.21 | 0.2752 |
| Model [6] | | | |

> [!IMPORTANT]
> Model [3] 相較於 Model [5] 為輕量化模型，參數量僅為 10.5%，運算量僅為 8.9%，推論速度快 3.4 倍。

---

### 3.2. 定性結果 (Qualitative Results)

根據課程 PDF 要求，以下為指定影像的視覺比較。報告中應以 **Input | Ground Truth | Model [3] | Model [5] | ...** 的格式並排展示各模型的輸出結果。

#### **指定視覺比較影像清單**

|        數據集        |      指定 Image ID      | 檔案位置                                         |
| :---------------: | :-------------------: | :------------------------------------------- |
| **SIR² Objects**  |     111, 032, 011     | `soild200-img/111.png`, `032.png`, `011.png` |
| **SIR² Postcard** |       019, 029        | `postcard199-img/019.png`, `029.png`         |
|   **SIR² Wild**   |          015          | `wild55-img/015.png`                         |
| **Berkeley Real** |          47           | `real20-img/47.png`                          |
| **CEILNet Real**  | qingnan-new2-22-input | `CEILNet-img/qingnan-new2-22-input.png`      |
|    **Nature**     |          3_1          | `nature20-img/3_1.png`                       |
|      **NRD**      |         I_093         | `NRD-img/093.png`                            |

> [!NOTE]
> 各模型的輸出影像分別位於：
> - **Model [3]**: `Models/Reflection_RemoVal_CVPR2024/SIRR_finetuned_seed21__test_results/`
> - **Model [5]**: `Models/Model5/RDNet/test_results/`

---

#### **視覺效果觀察**

根據上述指定影像的視覺結果，我們歸納以下觀察：

1. **SIR² Objects (011, 032, 111)**：兩模型皆能有效移除大部分反光。在影像 032 中，Model [3] 的 MaxRF 濾波器成功定位反射區域邊界，而 Model [5] RDNet 的可逆架構則保留了更多的高頻細節。影像 111 包含較為複雜的反射情況，兩模型的處理策略差異在此影像中更為明顯。

2. **SIR² Postcard (019, 029)**：Postcard 場景包含複雜的高頻紋理（如明信片上的文字與圖案），Model [5] 在細節保留上表現較佳，而 Model [3] 在反射移除的完整性上具有優勢。

3. **SIR² Wild (015)**：Wild 場景挑戰性較高，影像 015 包含強烈的戶外反射。兩模型皆留有部分殘餘反射，顯示野外場景中複雜光照與強反射仍是困難問題。

4. **Berkeley Real (47)**：該真實場景影像展現了訓練數據與真實數據之間的領域差異 (Domain Gap)。Model [3] 的位置感知機制在此類真實場景中展現較好的穩健性。

5. **CEILNet Real (qingnan-new2-22-input)**：此影像無 Ground Truth，僅供視覺定性比較。從視覺結果可觀察兩模型在真實無標註場景的處理效果。

6. **Nature (3_1)**：Model [3] 在 Nature 數據集整體表現較好（見 Table 1），該場景包含自然光照下的玻璃反射，Model [3] 的 MaxRF 物理先驗在此類場景更具優勢。

7. **NRD (I_093)**：高解析度 NRD 數據集考驗模型的泛化能力。從視覺結果可觀察 Model [5] 的可逆架構在保留細節方面的效果。

---

### 3.3. 討論與分析 (Discussion)

#### **3.3.1. 整體表現分析**

從 Table 1 的定量結果可以得出以下重要觀察：

1. **RDNet (Model [5]) 在 SIR2 數據集上全面領先**：在 SIR2 的三個子集（Objects, Postcard, Wild）以及整體評估中，RDNet 在 PSNR、SSIM、NCC 和 LPIPS 四項指標上均優於 Revisiting 模型。例如，在 SIR2-Objects 上，RDNet 的 PSNR 達到 **26.27 dB**，較 Revisiting 的 25.28 dB 高出約 1 dB（對應視覺品質的顯著提升）。

2. **Revisiting (Model [3]) 在 Nature20 數據集上表現更佳**：在 Nature20 真實場景數據集上，Revisiting 模型的 PSNR（25.17 dB vs 21.59 dB）與 SSIM（0.8353 vs 0.8001）均大幅領先。這可能歸因於其 **MaxRF 濾波器** 在處理自然場景中複雜反射分佈時的優勢，能更準確地區分「虛擬反射」與「真實背景」。

3. **Wild 場景的挑戰性**：兩模型在 SIR2-Wild 子集上的表現均低於 Objects 和 Postcard 子集。這印證了野外拍攝場景（如建築物玻璃、車窗等）因光照條件多變、反射強度不一而更具挑戰性。然而，RDNet 透過其 **透射率感知提示生成器 (TAPG)** 動態適應不同場景，在 Wild 子集上仍維持較高的 SSIM（0.9053 vs 0.8688）。

#### **3.3.2. 模型架構對效能的影響**

1. **可逆網絡的資訊保留優勢**：
   RDNet 採用的多列可逆編碼器 (MCRE) 確保了輸入影像的所有訊息都能無損地傳遞至深層網絡。這一設計在 SIR2-Objects（高解析度、細節豐富）和 Postcard（高頻紋理多）上帶來了顯著的 SSIM 提升，證實了可逆架構在保留結構資訊方面的有效性。

2. **位置感知機制的定位能力**：
   Revisiting 模型的 MaxRF 濾波器透過梯度分析顯式提取反射位置，在 Nature20 等真實數據上表現突出。這暗示了在反射分佈不規則的真實場景中，**先偵測、後移除** 的級聯策略可能比端對端學習更為穩健。

3. **推論效率的權衡**：
   從 Table 2 可見，Revisiting 模型的平均推論時間（0.0645 秒/影像）約為 RDNet（0.2744 秒/影像）的四分之一。這反映了 RDNet 較為複雜的可逆架構與提示生成機制帶來了額外的運算成本。在實際應用中，若對即時性有較高要求（如車載影像處理），Revisiting 模型可能是更合適的選擇。

#### **3.3.3. 在不同數據集上的泛化能力**

| 數據集類型 | 數據特性 | 最佳模型 | 分析 |
|------------|----------|----------|------|
| 合成數據 (SIR2-Objects) | 受控環境、清晰反射 | RDNet | 可逆架構有效保留細節 |
| 真實數據 (Nature20) | 複雜光照、多變場景 | Revisiting | MaxRF 的物理先驗更具優勢 |
| 野外場景 (Wild) | 高挑戰性、強反射 | RDNet | TAPG 動態適應能力較強 |

從上表可以觀察到，**兩模型各有所長**：RDNet 在受控環境下的精細處理表現優異，而 Revisiting 在真實複雜場景下展現了更好的穩健性。這與各自的設計理念相符——RDNet 著重於資訊無損傳遞，Revisiting 著重於反射的顯式定位。

#### **3.3.4. 待改進與未來方向**

1. **LMSE 指標標準化**：目前兩模型的 LMSE 計算方式不同，未來應統一計算方法以進行公平比較。

2. **NRD 數據集測試**：RDNet 在 NRD 數據集上的測試尚未完成，待補充以評估其在高解析度真實影像上的表現。

3. **輕量化模型探索**：考慮到 RDNet 較高的運算成本，結合 DExNet 的深度展開技術可能是在效能與效率間取得平衡的潛在方向。

---

### 3.4. 小結

綜合以上分析，在本次評估的兩個模型中：

- **若追求最佳視覺品質與定量指標**，在受控環境數據集上，**RDNet (Model [5])** 是首選，其可逆架構與提示生成機制帶來了全面的效能提升。

- **若追求泛化能力與真實場景表現**，**Revisiting (Model [3])** 的位置感知機制展現了更好的穩健性，特別是在 Nature20 等真實數據上。

- **若追求推論效率**，**Revisiting (Model [3])** 的速度優勢顯著，約為 RDNet 的 4 倍。

最終的「MVP 模型」選擇取決於具體應用場景的需求權衡。後續章節將整合所有六個模型的結果，提供更全面的比較分析。
