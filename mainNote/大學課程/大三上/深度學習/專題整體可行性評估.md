### 一、 可行性評估 (Feasibility Assessment)

**結論：高度可行，但時間緊迫，需策略性分配算力。**

1. **硬體能力 (RTX 4070 12GB):**
    
    - **算力：** 4070 的核心算力非常強大，支援 FP16 (混合精度訓練)，對於這種圖像修復任務（Image Restoration）來說綽綽有餘。
        
    - **VRAM (12GB)：** 這是唯一的瓶頸。
        
        - **DExNet, RDNet (CNN/Unfolding類)：** 參數量少（約 4M~10M），12GB 絕對夠用，甚至可以開大 Batch Size。
            
        - **DSIT (Transformer類)：** Transformer 模型對顯存消耗極大。在 12GB 顯存下，訓練 DSIT 可能需要將 Batch Size 設為 1 或 2，並配合 **Gradient Accumulation（梯度累積）** 技術來模擬大 Batch 的效果。
            
    - **訓練時間：** 單卡 4070 訓練一個 SIRR 模型（通常 Dataset 規模在 10k-14k 張圖），大約需要 **12~24 小時** (視 Epoch 數而定)。你有 4 個必選模型，總訓練時間約需 **4-5 天** 的連續運算。
        
2. **時間壓力 (13天倒數):**
    
    - 你需要訓練至少 4 個模型，還要跑測試、寫報告。
        
    - **建議策略：** 不要追求完美的超參數調優。先求「跑通」，再求「好」。優先完成必選的 [3], [4], [5], [6] 模型。

### 二、 具體耗時預估 (Time Estimation)

|**階段**|**任務內容**|**預估耗時**|**備註**|
|---|---|---|---|
|**P1**|**環境建置 & 資料下載**|1 天|資料集下載與整理最花時間|
|**P2**|**DExNet (TPAMI '25)**|1 天|輕量級，訓練快，優先執行以確保有數據|
|**P3**|**Revisiting (CVPR '24)**|1-2 天|架構中等|
|**P4**|**RDNet (CVPR '25)**|1-2 天|可逆網路，顯存優化較好|
|**P5**|**DSIT (NeurIPS '24)**|2-3 天|Transformer 訓練最慢，最容易 OOM (Out of Memory)|
|**P6**|**測試 & 數據彙整**|1-2 天|生成 PSNR/SSIM 表格與視覺化圖|
|**P7**|**報告撰寫**|2-3 天|需預留時間寫心得與分析|
|**緩衝**|Debug / 意外狀況|1-2 天||
#### 下載與整理資料集

根據 PDF 描述，資料集來源分散。建議建立以下目錄結構，方便所有模型共用，避免重複下載佔用空間：

Plaintext

```
Project_Root/
├── Datasets/
│   ├── train/
│   │   ├── VOC_synthetic/  (13,700 pairs)
│   │   ├── Real89/
│   │   ├── Nature200/
│   │   └── ...
│   └── test/
│       ├── Real20/
│       ├── SIR2/
│       ├── NRD/
│       └── ...
├── Models/
│   ├── DExNet/
│   ├── RDNet/
│   ├── DSIT/
│   └── ...
```

_注意：部分模型可能需要特定的資料夾結構，建議使用 Symbolic Link (符號連結) 來映射，不要複製檔案，節省 SSD 空間。_

### 四、 具體實作流程與針對性建議 (Step-by-Step)

請依照以下順序執行，由易到難：

#### **Step 1: DExNet (Model [6] - TPAMI 2025)**

- **連結:** `https://github.com/jjhuangcs/DExNet`
    
- **特點:** 輕量級、Deep Unfolding。這應該是最容易跑起來的模型。
    
- **操作:**
    
    1. Clone repo。
        
    2. 修改 `config` 檔中的 Dataset路徑指向你的 `Project_Root/Datasets`。
        
    3. 執行訓練。
        
    4. **注意:** 論文提到它是 "Lightweight" (約 9.66M 參數)，這是一個很好的 baseline。
        
    5. 利用 `thop` 庫計算 GFLOPs 填入 Table 2。
        

#### **Step 2: Revisiting SIRR (Model [3] - CVPR 2024)**

- **連結:** `https://github.com/zhuyr97/Reflection_RemoVal_CVPR2024`
    
- **特點:** 包含 Reflection Detection (RDNet) 和 Removal (RRNet) 兩個階段。
    
- **操作:**
    
    1. 注意它可能有兩階段訓練。如果是 End-to-End，直接訓練。如果是分開的，先訓 Detection 再訓 Removal。
        
    2. 它使用了 `MaxRF` (Maximum Reflection Filter)，確保你的資料預處理邏輯正確。
        

#### **Step 3: RDNet (Model [5] - CVPR 2025)**

- **連結:** `https://github.com/lime-j/RDNet`
    
- **特點:** 可逆神經網路 (Reversible Network)。
    
- **優勢:** 可逆網路在反向傳播時不需要儲存中間層的 activation，**非常節省顯存**。這對你的 12GB VRAM 很友善。
    
- **操作:** 按照官方 README 執行。注意它有一個 "Prompt Generator"，確保這部分有被正確載入或訓練。
    

#### **Step 4: DSIT (Model [4] - NeurIPS 2024) [大魔王]**

- **連結:** `https://github.com/mingcv/DSIT`
    
- **特點:** Dual-Stream Interactive Transformer。
    
- **挑戰:** Transformer 佔用顯存大。
    
- **4070 優化策略 (如果遇到 OOM):**
    
    1. **混合精度訓練 (AMP):** 確保程式碼中有使用 `torch.cuda.amp.autocast`。RTX 4070 在 FP16 下效能極佳且省顯存。
        
    2. **減小 Batch Size:** 設為 2 或 1。
        
    3. **梯度累積 (Gradient Accumulation):** 如果 Batch Size 設為 1，但論文建議 Batch Size 8，你可以在程式碼中設定 `accumulation_steps = 8`，每 8 次 forward 才做一次 `optimizer.step()`。
        
    4. **裁剪圖片:** 訓練時如果 $256 \times 256$ 跑不動，可以嘗試裁切成 $128 \times 128$ 或 $192 \times 192$ (雖然可能會稍微影響效果，但為了交作業跑通為主)。

### 五、 報告撰寫關鍵 (Report Strategy)

為了拿到高分，除了跑出數據，請在報告中強調以下幾點（基於你的 4070 本地端實作經驗）：

1. **Table 2 的計算:**
    
    - 你需要計算 `# of Parameters (M)` 和 `FLOPS (G)`。
        
    - 在 PyTorch 中使用以下代碼片段即可算出：
        
    
    Python
    
    ```python
    from thop import profile
    from thop import clever_format
    # 假設 model 是你的模型實例，input 是測試用的 dummy input (1, 3, 256, 256)
    input = torch.randn(1, 3, 256, 256).cuda()
    macs, params = profile(model, inputs=(input, ))
    macs, params = clever_format([macs, params], "%.3f")
    print(f"GFLOPs: {macs}, Params: {params}")
    ```
    
    - **Runtime (s):** 直接用你的 4070 跑 100 張測試圖取平均時間。
        
2. **視覺化比較:**
    
    - PDF 第 3 頁指定了要比較的圖片 (e.g., SIR2 objects: 111, 032...)。**務必只針對這些圖片做詳細並排比較**。
        
    - 截圖時，可以像論文一樣，放大細節 (Zoom in) 來展示模型是否成功去除了反光或是誤傷了背景。
        
3. **心得與討論:**
    
    - 提到 **CNN (DExNet)** vs **Transformer (DSIT)** 在 4070 上的訓練效率差異。
        
    - 提到 **RDNet (Reversible)** 對於顯存的節省效果。
        
    - 分析哪些模型在 "Wild" (野外場景) 表現更好（這通常是難點）。
        

### 六、 緊急救援 (如果跑不完)

如果到了 12/20 你發現訓練速度太慢，跑不完所有 Epoch：

1. **使用 Pre-trained Weights:** 這些 GitHub repo 通常會提供預訓練權重。
    
2. **微調 (Fine-tune):** 下載預訓練權重，在指定的 Dataset 上只訓練 5-10 個 Epoch（而不是從頭訓練 50-100 個）。
    
3. **在報告中誠實說明:** "由於硬體限制與時間因素，使用了官方預訓練模型進行 Fine-tuning..."，然後重點放在**測試數據的評估與分析**上。